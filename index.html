<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Russel Arbore's Website</title>
<meta name="description" content="Russel Arbore's personal website, created using Emacs + Org mode." />
<?php Header("Cache-Control: max-age=3000, must-revalidate"); ?>
<link rel="stylesheet" type="text/css" href="style.css" />
</head>
<body>
<div id="content" class="content">
<h1 class="title">Russel Arbore&rsquo;s Website</h1>

<div id="org04ee7ec" class="figure">
<p><img src="https://www.russelarbore.com/portrait.png" alt="portrait.png" width="250px" />
</p>
</div>

<div id="outline-container-orgbe6ccbe" class="outline-2">
<h2 id="orgbe6ccbe">Introduction</h2>
<div class="outline-text-2" id="text-orgbe6ccbe">
<p>
I&rsquo;m a freshman at the University of Illinois at Urbana-Champaign (UIUC) in Computer Science. I have experience in using PyTorch for training various deep learning models and in applying computer vision to real world data.
</p>
</div>
<div id="outline-container-org18d2ce4" class="outline-3">
<h3 id="org18d2ce4">You can reach me at&#x2026;</h3>
<div class="outline-text-3" id="text-org18d2ce4">
<ul class="org-ul">
<li>E-mail: <img src="https://www.russelarbore.com/email.png" alt="email.png" /></li>
<li>LinkedIn: Russel Arbore</li>
</ul>
</div>
</div>
</div>
<div id="outline-container-orgc609f2f" class="outline-2">
<h2 id="orgc609f2f">Work Experience</h2>
<div class="outline-text-2" id="text-orgc609f2f">
</div>
<div id="outline-container-orgeb13386" class="outline-3">
<h3 id="orgeb13386">Nelumbo</h3>
<div class="outline-text-3" id="text-orgeb13386">
<p>
At Nelumbo Inc., I created systems for quantifying the propagation of frost and condensation of droplets on custom hydrophobic surfaces. For measuring frost propagation, I developed a configurable pipeline for analyzing multiple time series of images from frost &amp; defrost cycles. For measuring droplet condensation, I tracked both droplet positions and radii within images individually and the behavior of droplets entering and leaving the surface.
</p>
<ul class="org-ul">
<li><a href="https://www.nelumbo.io/">https://www.nelumbo.io/</a></li>
</ul>
</div>
</div>
<div id="outline-container-org45ac0b4" class="outline-3">
<h3 id="org45ac0b4">Lamont-Doherty Earth Observatory</h3>
<div class="outline-text-3" id="text-org45ac0b4">
<p>
While working with the Lamont-Doherty Earth Observatory at Columbia University, I created and proved the viability of a novel method of data augmentation. This method was applied on a U-Net segmenting high-resolution satellite images of Antarctic fractures given only low-resolution images and labels for training.
</p>
<ul class="org-ul">
<li><a href="https://www.ldeo.columbia.edu/">https://www.ldeo.columbia.edu/</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgaeefb0c" class="outline-3">
<h3 id="orgaeefb0c">Invenio Imaging</h3>
<div class="outline-text-3" id="text-orgaeefb0c">
<p>
At Invenio Imaging, I created a Python framework for conducting validation tests on Invenio proprietary software and hardware and created tests covering a large portion of the software design spec.
</p>
<ul class="org-ul">
<li><a href="https://www.invenio-imaging.com/">https://www.invenio-imaging.com/</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org3596751" class="outline-2">
<h2 id="org3596751">Academic Projects</h2>
<div class="outline-text-2" id="text-org3596751">
</div>
<div id="outline-container-org1f4a4de" class="outline-3">
<h3 id="org1f4a4de">Using deep learning to non-iteratively conduct palette generation in class specific color quantization</h3>
<div class="outline-text-3" id="text-org1f4a4de">
<p>
Color quantization (CQ) is the process of reducing the amount of colors in an image with minimal loss in visual quality. The classical way of conducting CQ is by using K-Means to perform the palette generation step, which is fairly slow. This project investigated using a Convolutional Neural Network (CNN) to perform palette generation instead. We found that CNNs have the potential to perform on-par with K-Means in Mean Squared Error between the original and quantized images. Additionally, we found that CNNs have far lower runtimes than K-Means. As per our project title, we investigated whether CNNs were class specific and found that they were not. This means that CNNs can be generalized across many categories of images for CQ.
</p>
<ul class="org-ul">
<li><a href="https://www.github.com/RArbore/ASI_CQ">https://www.github.com/RArbore/ASI_CQ</a></li>
<li><a href="https://www.russelarbore.com/ASI-Final-Powerpoint.pptx">ASI Powerpoint</a></li>
</ul>
</div>
</div>
<div id="outline-container-org52143fb" class="outline-3">
<h3 id="org52143fb">Prototyping a deep learning based hearing aid for de-noising</h3>
<div class="outline-text-3" id="text-org52143fb">
<p>
Hearing aids today suffer from background noise that make their usage annoying for those with hearing loss. Traditional methods of conducting de-noising such as DNR don&rsquo;t account for complex noises, such as sounds resembling speech but are actually undesirable (crowded enviornments such as cafes or public spaces). We sought to instead use a deep learning model to conduct realtime de-noising. To accomplish this, we used a Jetson Nano 2GB to perform the de-noising. We chose a Fully Convolutional Neural Network (FCNN) as our de-noising model and trained on the Mozilla Common Voice dataset, the UrbanSound8K dataset, and data we collected ourselves.
</p>
<ul class="org-ul">
<li><a href="https://www.github.com/RArbore/Deep-Learning-Hearing-Aid">https://www.github.com/RArbore/Deep-Learning-Hearing-Aid</a></li>
<li><a href="https://www.russelarbore.com/Capstone-Final-Powerpoint.pptx">Capstone Powerpoint</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org527db40" class="outline-2">
<h2 id="org527db40">Personal Projects</h2>
<div class="outline-text-2" id="text-org527db40">
</div>
<div id="outline-container-orga69e632" class="outline-3">
<h3 id="orga69e632">rml</h3>
<div class="outline-text-3" id="text-orga69e632">
<p>
rml is a machine learning library under active development. rml is written in C and will allow for the training and deployment of deep learning models. Currently, rml has abstractions for basic tensor operations, tensor data types, and dynamic computational graph generation. OpenCL support is currently being worked on. A full TODO list can be seen on rml&rsquo;s GitHub page.
</p>
<ul class="org-ul">
<li><a href="https://www.github.com/RArbore/rml">https://www.github.com/RArbore/rml</a></li>
</ul>
</div>
</div>
<div id="outline-container-org4353b70" class="outline-3">
<h3 id="org4353b70">mnist-from-scratch</h3>
<div class="outline-text-3" id="text-org4353b70">
<p>
mnist-from-scratch is a from-scratch approach to training a deep learning model to identify numbers in images of handwritten digits. mnist-from-scratch uses only CUDA (C w/ the NVCC compiler) - no PyTorch, no Tensorflow, no Caffe! mnist-from-scratch is not meant to be extensible to other deep learning problems - it is simply a &lt;500 line example of training a neural network from scratch.
</p>
<ul class="org-ul">
<li><a href="https://www.github.com/RArbore/mnist-from-scratch">https://www.github.com/RArbore/mnist-from-scratch</a></li>
<li>Note, if you want to try running this yourself, you will need .csv versions of the MNIST dataset. I couldn&rsquo;t upload my versions of these files to GitHub due to file size limits, so you can find them here:
<ul class="org-ul">
<li><a href="https://www.russelarbore.com/images.csv">https://www.russelarbore.com/images.csv</a></li>
<li><a href="https://www.russelarbore.com/labels.csv">https://www.russelarbore.com/labels.csv</a></li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgfe8fd55" class="outline-3">
<h3 id="orgfe8fd55">glfw-voxel</h3>
<div class="outline-text-3" id="text-orgfe8fd55">
<p>
glfw-voxel is a simple voxel-based rendering engine focused on speed. glfw-voxel is written in C, and uses OpenGL/GLFW for rendering. glfw-voxel optimizes chunk meshing to minimize faces that need to be rendered; it also uses frustrum culling. glfw-voxel uses the cglm linear algebra library.
</p>
<ul class="org-ul">
<li><a href="https://www.github.com/RArbore/glfw-voxel">https://www.github.com/RArbore/glfw-voxel</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgba25116" class="outline-3">
<h3 id="orgba25116">rphys</h3>
<div class="outline-text-3" id="text-orgba25116">
<p>
rphys is a dead-simple elastic collision physics engine. rphys uses OpenGL/GLFW for rendering.
</p>
<ul class="org-ul">
<li><a href="https://www.github.com/RArbore/rphys">https://www.github.com/RArbore/rphys</a></li>
</ul>
</div>
</div>
<div id="outline-container-orgcbb1880" class="outline-3">
<h3 id="orgcbb1880">cuda-simulation</h3>
<div class="outline-text-3" id="text-orgcbb1880">
<p>
cuda-simulation is a simple demonstration of using CUDA to simulate a cellular automaton. This project is written in C, uses CUDA for GPU computation, and uses OpenGL/GLUT for rendering.
</p>
<ul class="org-ul">
<li><a href="https://www.github.com/RArbore/cuda-simulation">https://www.github.com/RArbore/cuda-simulation</a></li>
</ul>
</div>
</div>
</div>
<div id="outline-container-org396da16" class="outline-2">
<h2 id="org396da16">Notes</h2>
<div class="outline-text-2" id="text-org396da16">
<p>
You can find a library of my personal notes here: <a href="https://www.russelarbore.com/notes.html">Notes</a>
</p>
</div>
</div>
</div>
</body>
</html>
